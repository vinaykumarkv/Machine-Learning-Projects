{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adverse Event Detection in Pharmacovigilance (v0.1)\n",
    "## Objective\n",
    "To build a basic system to detect adverse events (AEs) from text input (e.g., patient reports) using keyword matching and a SQLite database for drug-side effect lookup. \n",
    "This is 0.1v for a pharmacovigilance NLP project, focusing on data prep and basic NLP.\n",
    "## Features- \n",
    "Load and clean text data (synthetic AE reports).\n",
    "- Store drug-side effect pairs in SQLite.\n",
    "- Tokenize text and match AE keywords with simple negation handling.\n",
    "- Output: 'AE detected: <symptom>' or 'No AE detected'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vinay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\vinay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sqlite3 #db actions\n",
    "import nltk #this is a word processing library which can find context and sarcasm etc, used for tokenizing the text\n",
    "\n",
    "nltk.download('punkt') #used for word or sentence spliting\n",
    "nltk.download('punkt_tab') #used for word or sentence spliting\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize #importing word tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Data Collection and Preparation\n",
    "Loading synthetic data similar to AE reports, cleaning the text, and creating a SQLite DB for drug-side effect pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will be using small synthetic dataset for v0.1 - I will try replacing with real dataset in next version\n",
    "data = pd.DataFrame({\n",
    "    'report_id': [1, 2, 3, 4,5,6],\n",
    "    'text': [\n",
    "        'I took Aspirin and felt severe dizzy',\n",
    "        'After DrugX, no nausea reported',\n",
    "        'Ibuprofen caused severe headache',\n",
    "        'Took DrugY, feeling great',\n",
    "        'I inhaled DrugV, feeling mild dizzy',\n",
    "        'I applied LotionX, I felt severe fatigue',\n",
    "    ],\n",
    "    \"severity\":[\n",
    "        'severe',\n",
    "        'none',\n",
    "        'severe',\n",
    "        'none',\n",
    "        'mild',\n",
    "        'severe',\n",
    "    ],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data:\n",
      "   report_id                               text_clean\n",
      "0          1     i took aspirin and felt severe dizzy\n",
      "1          2           after drugx no nausea reported\n",
      "2          3         ibuprofen caused severe headache\n",
      "3          4                 took drugy feeling great\n",
      "4          5       i inhaled drugv feeling mild dizzy\n",
      "5          6  i applied lotionx i felt severe fatigue\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cleaning text by removing space, tabs, characters and removing caps and making it lower case\n",
    "data['text_clean'] = data['text'].str.lower().str.replace('[^a-zA-Z\\s]', '', regex=True)\n",
    "\n",
    "#lets see the cleaned data\n",
    "print('Cleaned Data:')\n",
    "print(data[['report_id', 'text_clean']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x296ef5260c0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating SQLite DB for drug-side effect pairs\n",
    "conn = sqlite3.connect('ae_database.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS drug_side_effects (\n",
    "        drug TEXT,\n",
    "        side_effect TEXT\n",
    "    )\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets add sample data into side effects\n",
    "side_effects = [\n",
    "    ('Aspirin', 'dizzy'),\n",
    "    ('Aspirin', 'nausea'),\n",
    "    ('Ibuprofen', 'headache'),\n",
    "    ('DrugX', 'nausea'),\n",
    "    ('DrugV', 'dizzy'),\n",
    "    ('LotionX', 'fatigue'),\n",
    "]\n",
    "cursor.executemany('INSERT OR REPLACE INTO drug_side_effects VALUES (?, ?)', side_effects)\n",
    "conn.commit() #commiting the changes to DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Drug-Side Effect Table:\n",
      "[('Aspirin', 'dizzy'), ('Aspirin', 'nausea'), ('Aspirin', 'dizzy'), ('Aspirin', 'nausea'), ('Aspirin', 'dizzy'), ('Aspirin', 'nausea'), ('Aspirin', 'dizzy'), ('Aspirin', 'nausea')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# checking the data in table\n",
    "cursor.execute(\"SELECT * FROM drug_side_effects WHERE drug = 'Aspirin'\")\n",
    "print('\\nDrug-Side Effect Table:')\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Basic NLP PipelineTokenize text, match AE keywords, and handle simple negation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adverse event key words as we defined earlier, we will add more of these in next versions\n",
    "ae_keywords = {'dizzy', 'nausea', 'headache', \"fatigue\", \"rash\",\"allergy\"}\n",
    "\n",
    "\n",
    "#lets create a function to tokenize the text and check if any adverse events have happenend\n",
    "def detect_ae(text, keywords, conn):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Check for negation - will add more words later version if required this will help in identifying negative statements\n",
    "    negation_words = {'no', 'not', 'never'}\n",
    "    detected_aEs = [] #initiatizing the list\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in keywords:\n",
    "            if i > 0 and tokens[i-1] in negation_words:  # Check previous word for negation and skip if yes\n",
    "                continue\n",
    "            # ortherwise continue checking\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute('SELECT drug FROM drug_side_effects WHERE side_effect = ?', (token,)) #compare the token with table and fetch matching\n",
    "            drugs = cursor.fetchall() #assigning fetched values into drugs\n",
    "            if drugs: #if value is present then add to list\n",
    "                detected_aEs.append(token)\n",
    "    return detected_aEs #finally return the detected adverse event\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "   report_id                                      text  \\\n",
      "0          1      I took Aspirin and felt severe dizzy   \n",
      "1          2           After DrugX, no nausea reported   \n",
      "2          3          Ibuprofen caused severe headache   \n",
      "3          4                 Took DrugY, feeling great   \n",
      "4          5       I inhaled DrugV, feeling mild dizzy   \n",
      "5          6  I applied LotionX, I felt severe fatigue   \n",
      "\n",
      "                      result  \n",
      "0     AE detected: ['dizzy']  \n",
      "1             No AE detected  \n",
      "2  AE detected: ['headache']  \n",
      "3             No AE detected  \n",
      "4     AE detected: ['dizzy']  \n",
      "5   AE detected: ['fatigue']  \n"
     ]
    }
   ],
   "source": [
    "# Process reports\n",
    "data['detected_aEs'] = data['text_clean'].apply(lambda x: detect_ae(x, ae_keywords, conn)) # applying the function to each row of the dataframe\n",
    "data['result'] = data['detected_aEs'].apply(lambda x: f'AE detected: {x}' if x else 'No AE detected') #if drug is found in adverse event then show as detected or else state not found\n",
    "\n",
    "print('\\nResults:')\n",
    "print(data[['report_id', 'text', 'result']])\n",
    "\n",
    "# Close database\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Prepare for Severity Classification\n",
    "Add data for logistic regression to classify AE severity (mild/severe). - will continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
